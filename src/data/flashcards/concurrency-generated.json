{
  "topic": "concurrency",
  "generated_at": "2026-01-16T04:04:09.898302+00:00",
  "cards": [
    {
      "id": "concurrency_0a59c109c99a",
      "front": "Actors are said to eliminate data races for their internal state. Explain the mechanism of 'actor isolation' that enables this. How does it affect access to actor properties/methods, and what is the significance of reentrancy in this model?",
      "back": "### Core Concept\n\nActor isolation is a compile-time mechanism that protects an actor's mutable state from concurrent access, thus preventing data races. An actor ensures that only one piece of code can access its state at any given time. This is achieved by placing its state and methods behind a 'mailbox' that serializes incoming requests.\n\n1.  **Synchronous Internal Access**: Code running within the actor's own methods can access its properties and other methods synchronously and directly (e.g., using `self`).\n2.  **Asynchronous External Access**: Any code outside the actor must access its mutable state asynchronously. The compiler enforces this by requiring you to use `await`. This `await` signals a potential suspension point where the calling task yields the thread, allowing the actor's serial executor to process the next message in its queue.\n\n**Reentrancy**: A crucial and subtle aspect of actors. When an actor method `await`s an async call, it suspends and gives up its thread. During this suspension, the actor is *not* blocked; it can process other messages from its mailbox. When the awaited call completes, the method resumes. This means the actor's state may have been modified by other calls between the `await` and the resumption. This prevents deadlocks but requires developers to re-verify state after `await`ing.\n\n### Practical Code Example\n```swift\nactor BankAccount {\n    private var balance: Double\n\n    // nonisolated allows synchronous access from outside\n    // because it accesses only immutable state.\n    nonisolated let accountID: UUID\n\n    init(initialDeposit: Double, id: UUID) {\n        self.balance = initialDeposit\n        self.accountID = id\n    }\n\n    func deposit(amount: Double) {\n        // Synchronous access inside the actor is safe.\n        balance += amount\n    }\n\n    // This method is reentrant.\n    func transfer(amount: Double, to otherAccount: BankAccount) async throws {\n        // 1. State check\n        guard balance >= amount else { throw BankError.insufficientFunds }\n\n        // 2. Suspension point (await). The actor is now free to process other tasks.\n        // Another task could withdraw funds here, making the initial check invalid!\n        await otherAccount.deposit(amount: amount)\n\n        // 3. Resumption. State might have changed. A robust implementation\n        // would re-verify or perform the withdrawal before the deposit.\n        balance -= amount \n    }\n}\n```\n\n### Common Pitfalls\n\n*   **Reentrancy Bugs**: Assuming actor state is unchanged across an `await`. Always re-validate assumptions after a suspension point if your logic depends on it.\n*   **Actor Deadlocks**: While reentrancy prevents many deadlocks, they can still occur. E.g., Actor A `await`s a result from Actor B, while Actor B simultaneously `await`s a result from Actor A.\n*   **Overusing `nonisolated`**: Applying `nonisolated` to a function that accesses mutable state breaks the actor's protection and can re-introduce data races. It should only be used for immutable data or thread-safe operations.\n\n### When to Use vs. Alternatives\n\n*   **Use Actors**: When you need to manage and protect shared, mutable state. They are the modern, preferred Swift solution for synchronizing access to a resource like a cache, data repository, or state manager.\n*   **Alternatives**:\n    *   **Serial `DispatchQueue`**: The traditional GCD approach. Actors provide stronger compile-time safety and integrate more cleanly with `async/await` syntax.\n    *   **Locks (`NSLock`, `os_unfair_lock`)**: Lower-level and potentially more performant for highly contended, short critical sections. However, they are manual, error-prone (forgetting to unlock), and risk deadlocks and priority inversion.\n    *   **Value Types (`struct`)**: The best alternative is to avoid shared mutable state entirely. Using immutable value types eliminates the possibility of data races by design.",
      "code_example": null,
      "tags": [
        "concurrency",
        "actors",
        "swift"
      ],
      "sources": [
        "https://www.objc.io/issues/2-concurrency/concurrency-apis-and-pitfalls/"
      ]
    },
    {
      "id": "concurrency_63f51f17b095",
      "front": "Explain how @MainActor is a specific implementation of a global actor. Describe a scenario where you'd create a custom global actor, and contrast its thread-safety guarantees with using a standard actor or a serial DispatchQueue.",
      "back": "### Core Concept\n\nA global actor is a mechanism in Swift Concurrency that provides a globally unique, mutually exclusive execution context. It ensures that any code marked with its attribute (functions, properties, or entire types) runs serially, preventing data races on a shared resource across the entire application.\n\n`@MainActor` is the most common example of a global actor. It's provided by the standard library, and its singleton executor is the main application thread. By annotating UI-related code with `@MainActor`, you instruct the compiler to enforce that this code is only ever executed on the main thread, guaranteeing UI safety.\n\nYou would create a custom global actor to protect a resource that is inherently a singleton and requires coordinated access from disparate parts of your app. Examples include a persistent storage coordinator (like a single database connection), a file manager, or a centralized logging service.\n\n### Practical Code Example\n\nLet's create a global actor to serialize all access to a logging service.\n\n```swift\n// 1. Define the custom global actor\n@globalActor\nstruct LoggerActor {\n  // The compiler uses this shared instance to create the global executor.\n  static let shared = ActorType()\n  typealias ActorType = Actor\n}\n\n// 2. Isolate a class to the global actor\n// All methods and properties in this class will run on the LoggerActor.\n@LoggerActor\nclass FileLogger {\n  private let fileHandle: FileHandle\n\n  init() { /* ... open file handle ... */ }\n\n  func log(_ message: String) {\n    // This is guaranteed to be serialized, preventing garbled writes.\n    let line = \"\\(Date()): \\(message)\\n\"\n    fileHandle.write(line.data(using: .utf8)!)\n  }\n}\n\n// 3. Use it from a different context (e.g., the MainActor)\n@MainActor\nclass MyViewModel {\n  let logger = FileLogger()\n\n  func onButtonTapped() async {\n    // 'await' is required to hop from MainActor to LoggerActor.\n    // The compiler enforces this context switch for thread safety.\n    await logger.log(\"Button was tapped by user.\")\n  }\n}\n```\n\n### Comparison & Pitfalls\n\n*   **Global Actor vs. Standard Actor**: Use a standard `actor` to protect the state of a single *instance*. Use a `@globalActor` when you need to serialize access to a single, app-wide resource that has no specific instance owner (or is a singleton).\n\n*   **Global Actor vs. Serial `DispatchQueue`**:\n    *   **Safety**: A global actor provides **compile-time safety**. The compiler forces you to `await` calls from other contexts, preventing accidental data races. A `DispatchQueue` provides **run-time safety**; you must manually wrap access in `queue.sync/async`, and the compiler cannot detect if you forget. This is the primary advantage of actors.\n    *   **Bottlenecks**: Both can become a performance bottleneck. Any long-running, synchronous work on a global actor will block *all other tasks* waiting to use that shared resource. This is a critical pitfall to avoid. Always use `await` for I/O or other suspending work inside an actor.\n    *   **Integration**: Global actors are native to `async/await`, leading to cleaner, more readable code without the nested closures common with `DispatchQueue`.",
      "code_example": null,
      "tags": [
        "concurrency",
        "actors",
        "swift-concurrency",
        "mainactor",
        "architecture"
      ],
      "sources": [
        "https://www.objc.io/issues/2-concurrency/concurrency-apis-and-pitfalls/"
      ]
    },
    {
      "id": "concurrency_b2a458c2caac",
      "front": "Explain the relationship between `AsyncSequence` and `AsyncStream`. When would you create a custom type conforming to `AsyncSequence` vs. using `AsyncStream`?",
      "back": "`AsyncSequence` is a protocol, analogous to `Sequence`, that defines a sequence of values produced asynchronously. It enables iteration using a `for await...in` loop, which pulls values from the sequence one by one. You would implement this protocol directly when you are creating a new, complex, pull-based asynchronous data source, such as a custom network client that handles paginated results. The consumer drives the iteration by requesting the next item.\n\n`AsyncStream`, on the other hand, is a concrete type that conforms to `AsyncSequence`. Its primary role is to act as a bridge, adapting existing, non-structured, push-based event sources into the structured world of Swift Concurrency. It's ideal for wrapping APIs that use delegates, callbacks, or notifications, which push data to your app unpredictably. You provide `AsyncStream` a closure where you receive a `continuation`. You use this continuation to `yield` values as they arrive from the legacy API and `finish` the stream when the source is exhausted.\n\n```swift\nimport CoreLocation\n\n// Example: Bridging a delegate-based API (CLLocationManager) using AsyncStream\nclass LocationManager: NSObject, CLLocationManagerDelegate {\n    private let manager = CLLocationManager()\n    private var continuation: AsyncStream<CLLocation>.Continuation?\n\n    var locations: AsyncStream<CLLocation> {\n        AsyncStream { continuation in\n            self.continuation = continuation\n            self.manager.delegate = self\n            self.manager.startUpdatingLocation()\n\n            continuation.onTermination = { @Sendable [weak self] _ in\n                self?.manager.stopUpdatingLocation()\n            }\n        }\n    }\n\n    func locationManager(_ manager: CLLocationManager, didUpdateLocations locations: [CLLocation]) {\n        locations.forEach { continuation?.yield($0) }\n    }\n\n    func locationManager(_ manager: CLLocationManager, didFailWithError error: Error) {\n        // In a real app, you might yield an error instead.\n        continuation?.finish()\n    }\n}\n\n// Usage:\n// let locationManager = LocationManager()\n// for await location in locationManager.locations {\n//     print(\"New location: \\(location.coordinate)\")\n//     // The loop will continue indefinitely until the stream is finished.\n// }\n```\n\n### Common Pitfalls:\n- **Forgetting to Finish:** If `continuation.finish()` is never called, any `for await` loop consuming the stream will hang indefinitely, leaking resources.\n- **Backpressure:** `AsyncStream` can buffer results if the producer is faster than the consumer. Using the default `.unbounded` policy can lead to high memory usage. Consider policies like `.bufferingNewest(1)` for cases like location updates where you only care about the latest value.\n- **Continuation Misuse:** The continuation is not thread-safe and should not be stored outside the stream's initialization closure. Access must be synchronized if events can arrive on different threads.\n\n### When to Use vs. Alternatives:\n- **Custom `AsyncSequence`:** Use for creating a new, stateful, pull-based sequence. E.g., a sequence that fetches pages from a web API. The `next()` method of your iterator would contain the logic to fetch the next page *only when the consumer is ready for it*.\n- **`AsyncStream`:** Use as an adapter for existing push-based code. It's the go-to tool for integrating older asynchronous patterns into modern Swift Concurrency.",
      "code_example": null,
      "tags": [
        "concurrency",
        "swift-concurrency",
        "asyncsequence",
        "asyncstream",
        "structured-concurrency"
      ],
      "sources": [
        "https://www.objc.io/issues/2-concurrency/concurrency-apis-and-pitfalls/",
        "https://www.objc.io/issues/2-concurrency/common-background-practices/"
      ]
    },
    {
      "id": "concurrency_dbfc3f91d97e",
      "front": "Compare and contrast using Actors, serial dispatch queues, and locks (e.g., NSLock) for preventing data races in Swift. Discuss the trade-offs and when you would choose each approach.",
      "back": "A data race occurs when multiple threads access shared mutable state without synchronization, with at least one access being a write. Swift offers several mechanisms to prevent this, each with distinct trade-offs.\n\n**Core Concepts:**\n1.  **Actors:** A reference type that protects its state from concurrent access. The Swift compiler guarantees that only one task can access the actor's state at a time, serializing access through an internal \"mailbox.\" This provides compile-time safety, making it the most modern and safest approach.\n2.  **Serial Dispatch Queue (GCD):** A classic approach where all access to a shared resource is dispatched onto a single serial queue. GCD guarantees that tasks on this queue execute one at a time, in FIFO order, thus serializing access and preventing races.\n3.  **Locks (`NSLock`):** A low-level mutex. A thread must acquire the lock before entering a \"critical section\" (code accessing the shared resource) and release it upon exit. This is a manual and error-prone approach but offers fine-grained control.\n\n**Code Example:**\n```swift\n// 1. Actor: Compiler-enforced safety\nactor CounterActor {\n    private var value = 0\n    func increment() -> Int {\n        value += 1\n        return value\n    }\n}\n\n// 2. Serial Queue: Manual serialization\nclass CounterQueue {\n    private var value = 0\n    private let queue = DispatchQueue(label: \"com.example.counterQueue\")\n    func increment() -> Int {\n        queue.sync { // sync ensures the value is returned after mutation\n            self.value += 1\n            return self.value\n        }\n    }\n}\n\n// 3. Lock: Manual, low-level control\nclass CounterLock {\n    private var value = 0\n    private let lock = NSLock()\n    func increment() -> Int {\n        lock.lock()\n        defer { lock.unlock() } // `defer` guarantees unlock, even on error\n        value += 1\n        return value\n    }\n}\n```\n\n**Pitfalls & Trade-offs:**\n*   **Actors:** Can experience re-entrancy. If an actor method suspends (on an `await`), another method can start running, which can break invariants if not handled carefully. They are part of the structured concurrency model and work best with `async/await`.\n*   **Queues:** Risk of deadlocks (e.g., calling `sync` on a queue from a task already on it). Can cause priority inversion if a low-priority task holds up a high-priority one.\n*   **Locks:** Highest risk. Forgetting to unlock leads to deadlocks. High lock contention can degrade performance. They do not compose well with `async/await` as holding a lock across a suspension point is a major anti-pattern.\n\n**When to Use:**\n*   **Actors:** The default choice for new code using `async/await`. Ideal for protecting the state of an object/class.\n*   **Serial Queues:** Best for interfacing with older GCD-based APIs or when you need to coordinate access to a resource that isn't easily modeled as an actor (e.g., file system). Also useful when strict FIFO ordering is a hard requirement.\n*   **Locks:** Use sparingly for performance-critical, short-lived critical sections where the overhead of GCD or actors is unacceptable. It's a last resort for fine-grained optimization.",
      "code_example": null,
      "tags": [
        "concurrency",
        "data race",
        "actor",
        "gcd",
        "locks",
        "swift structured concurrency"
      ],
      "sources": [
        "https://www.objc.io/issues/2-concurrency/concurrency-apis-and-pitfalls/"
      ]
    },
    {
      "id": "concurrency_c4f511d6cdf5",
      "front": "How does the `Sendable` protocol enhance thread safety in Swift's modern concurrency model, and how does its compile-time checking differ from traditional lock-based mechanisms?",
      "back": "The `Sendable` protocol is a cornerstone of Swift's modern concurrency model, acting as a compile-time contract that a type's values can be safely transferred between different concurrency domains (e.g., between actors or threads) without causing data races. It is a marker protocol, meaning it has no required methods or properties; its sole purpose is to be checked by the Swift compiler.\n\n**Core Concept:**\nBefore `Sendable`, thread safety was a runtime concern, managed manually with locks, serial queues, or other synchronization primitives. This approach is error-prone, leading to issues like deadlocks, race conditions, and priority inversion that are difficult to debug. `Sendable` shifts this responsibility to the compiler. When you pass a value across a concurrency boundary (e.g., as an argument to an actor method), the compiler verifies that the type conforms to `Sendable`. If it doesn't, a compile-time error is generated, preventing the potential data race before the app is even run.\n\n- **Value Types (structs, enums):** Conform implicitly if all their stored properties are also `Sendable`.\n- **Reference Types (classes):** Must be `final`, have only immutable stored properties (or internally synchronized mutable state), and if they subclass, their superclass must be `Sendable` (like `NSObject`).\n- **Actors:** Are implicitly `Sendable` as they manage their own state safely.\n\n**Practical Code Example:**\n```swift\n// Implicitly Sendable struct\nstruct UserProfile: Sendable {\n    let id: UUID\n    let username: String\n}\n\n// A class that is NOT Sendable due to mutable state\nclass UserSession {\n    var loginCount: Int = 0 // Mutable property makes this unsafe to share\n}\n\n// An actor that processes user data\nactor DataProcessor {\n    func processProfile(_ profile: UserProfile) -> Bool {\n        // This is safe: UserProfile is Sendable\n        print(\"Processing \\(profile.username)\")\n        return true\n    }\n    \n    func processSession(_ session: UserSession) {\n        // COMPILE ERROR: Non-sendable type 'UserSession' cannot be passed\n        // across actor boundaries.\n        print(\"Session has \\(session.loginCount) logins\")\n    }\n}\n```\n\n**Common Pitfalls or Edge Cases:**\n- **`@unchecked Sendable`:** This is an escape hatch to tell the compiler \"trust me, this type is safe,\" even if it can't prove it. It's used for types that use internal locking (like a class wrapping an `os_unfair_lock`) to manage their own thread safety. Misusing it bypasses compiler checks and can reintroduce data races.\n- **Mutable State in Classes:** A common mistake is to conform a class with `var` properties to `Sendable` without any synchronization. This is incorrect and dangerous. The state must be immutable or protected by a synchronization mechanism.\n- **Function Types:** Closures and function types are `Sendable` only if they are non-escaping and capture only `Sendable` values.\n\n**When to Use vs. Alternatives:**\n- **`Sendable` & Actors:** Use for all new concurrent code in Swift. It provides compile-time safety, which is far superior to runtime checks. It makes concurrent code easier to reason about and maintain.\n- **Locks (`NSLock`) / Serial Queues (GCD):** These are traditional, runtime-based synchronization mechanisms. They are still necessary when interacting with legacy Objective-C code or in performance-critical paths where the overhead of actors is a concern. However, they lack compile-time safety, placing the full burden of correctness on the developer and making bugs like deadlocks and race conditions possible.",
      "code_example": null,
      "tags": [
        "concurrency",
        "swift-concurrency",
        "sendable",
        "actors",
        "thread-safety",
        "data-race"
      ],
      "sources": [
        "https://www.objc.io/issues/2-concurrency/concurrency-apis-and-pitfalls/"
      ]
    },
    {
      "id": "concurrency_ef63c6d3be70",
      "front": "Explain the parent-child task hierarchy in Swift's Structured Concurrency and how it improves task lifetime management, cancellation, and error propagation over older APIs like GCD.",
      "back": "Structured Concurrency treats concurrent operations as a hierarchy of tasks. When a function creates a new asynchronous task using `async let` or a `TaskGroup`, that new task becomes a child of the current task. This structure provides compile-time safety and guarantees that a parent task cannot complete until all of its child tasks have finished.\n\nThis model is a significant improvement over APIs like Grand Central Dispatch (GCD) for three key reasons:\n1.  **Scoped Lifetime:** A child task's lifetime is strictly contained within its parent's scope. This prevents tasks from 'leaking' and running indefinitely after they are no longer needed, which is a common issue with fire-and-forget GCD dispatches.\n2.  **Automatic Cancellation:** If a parent task is cancelled, the cancellation is automatically and transparently propagated to all its children and their descendants. In GCD or `OperationQueue`, cancellation is a manual, often error-prone process of checking a flag.\n3.  **Error Propagation:** An error thrown by any child task is automatically propagated up to the parent, where it can be caught and handled. This prevents silent failures where a background task might fail without the calling code ever knowing.\n\n**Code Example (`async let`):**\n```swift\nfunc fetchContent(for userID: String) async throws -> (Profile, [Post]) {\n    // `async let` creates two child tasks that run concurrently.\n    // The parent task (running `fetchContent`) owns them.\n    async let profileTask = api.fetchProfile(for: userID)\n    async let postsTask = api.fetchPosts(for: userID)\n    \n    // The function scope will not exit until both child tasks complete.\n    // `await` retrieves the results. If a child task threw an error,\n    // `await` re-throws it here, ensuring errors are handled.\n    let profile = try await profileTask\n    let posts = try await postsTask\n    \n    return (profile, posts)\n}\n```\n\n**Common Pitfalls:**\n*   **Unstructured Detachment:** Using `Task.detached` unnecessarily. This creates a new top-level task with no parent, breaking the structure and losing all its benefits. It should only be used for tasks that must outlive the current scope.\n*   **Ignoring `async let` Errors:** Declaring an `async let` but never `await`-ing it. The task runs, but if it throws an error, the error is silently discarded.\n\n**When to Use vs. Alternatives:**\n*   **Structured Concurrency (`async let`/`TaskGroup`):** The default for all new concurrent code in Swift. Use `async let` for a fixed number of concurrent tasks. Use `TaskGroup` for a dynamic number of tasks.\n*   **GCD/`OperationQueue`:** Use for interoperating with legacy code or for specific features like `OperationQueue`'s dependency management, which is more powerful than task dependencies. However, prefer Structured Concurrency for its superior safety and clarity.",
      "code_example": null,
      "tags": [
        "Concurrency",
        "Swift Concurrency",
        "Structured Concurrency",
        "TaskGroup",
        "async let"
      ],
      "sources": [
        "https://www.objc.io/issues/2-concurrency/concurrency-apis-and-pitfalls/"
      ]
    },
    {
      "id": "concurrency_adf2fcd2570c",
      "front": "Explain how `TaskGroup` handles child task results, failures, and cancellation. How does its structured approach differ from launching multiple unstructured `Task`s?",
      "back": "A `TaskGroup` is a core tool for structured concurrency in Swift, allowing you to create a dynamic number of child tasks that run in parallel within a well-defined scope.\n\n**Core Concept:**\nThe `withTaskGroup` (or `withThrowingTaskGroup`) function creates a scope for concurrency. The parent task that calls this function is suspended until all child tasks added to the group have completed. This parent-child relationship is the essence of structured concurrency. \n\n- **Results:** Results from child tasks are delivered asynchronously as they finish. You can iterate over them using a `for await` loop. The order of results is not guaranteed to match the order tasks were added.\n- **Failures:** When using `withThrowingTaskGroup`, if any child task throws an error, the group is immediately cancelled. All other running child tasks are notified of the cancellation. The `withThrowingTaskGroup` call then rethrows the error from the first task that failed.\n- **Cancellation:** Cancellation is propagated downwards. If the parent task containing the group is cancelled, the group and all its children are cancelled. You can also explicitly call `group.cancelAll()` to cancel all child tasks.\n\nThis contrasts sharply with unstructured `Task`s, which are 'fire-and-forget'. They have no inherent parent-child relationship, so the parent task does not wait for them, and cancellation does not automatically propagate.\n\n**Code Example:**\n```swift\n// Fetches multiple image URLs concurrently and returns the first successful one.\nenum FetchError: Error { case allFailed }\n\nfunc fetchFirstCompletedImage(from urls: [URL]) async throws -> UIImage? {\n    return try await withThrowingTaskGroup(of: UIImage?.self) { group in\n        // Dynamically add a child task for each URL.\n        for url in urls {\n            group.addTask { \n                // Each task attempts to fetch and create an image.\n                // It can return nil or throw an error on failure.\n                let (data, _) = try await URLSession.shared.data(from: url)\n                return UIImage(data: data)\n            }\n        }\n\n        // Iterate through results as they complete.\n        for try await image in group {\n            if let validImage = image {\n                // Got a valid image. Cancel remaining tasks and return.\n                group.cancelAll() \n                return validImage\n            }\n        }\n        \n        // If the loop finishes, no task returned a valid image.\n        throw FetchError.allFailed\n    }\n}\n```\n\n**Common Pitfalls & Edge Cases:**\n- **Forgetting to Iterate:** Not consuming results with `for await` can be a mistake. The group's scope will still wait for all tasks to finish, but you won't get their output.\n- **Error Handling:** Only the *first* error thrown by a child task is propagated. Subsequent errors from other tasks are ignored.\n- **Result Ordering:** Relying on the order of results is a common bug. They arrive as tasks complete, which is non-deterministic.\n\n**When to use vs. Alternatives:**\n- **Use `TaskGroup`:** For a dynamic, unknown number of concurrent tasks, especially when you need to process results as they arrive or aggregate them (e.g., fetching data for a list of IDs).\n- **Use `async let`:** For a small, *fixed* number of concurrent tasks known at compile time. The syntax is simpler, and it's ideal for fetching heterogeneous data (e.g., a user profile and their settings simultaneously).",
      "code_example": null,
      "tags": [
        "concurrency",
        "swift-concurrency",
        "structured-concurrency",
        "taskgroup"
      ],
      "sources": [
        "https://www.objc.io/issues/2-concurrency/concurrency-apis-and-pitfalls/"
      ]
    }
  ]
}