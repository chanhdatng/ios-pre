{
  "topic": "concurrency",
  "generated_at": "2026-01-13T04:04:10.582283+00:00",
  "cards": [
    {
      "id": "concurrency_c4f511d6cdf5",
      "front": "Explain how the `Sendable` protocol and its compiler checks prevent data races in Swift's structured concurrency. What types are implicitly `Sendable`, and when would you need to explicitly or unsafely conform a custom type?",
      "back": "The `Sendable` protocol is a cornerstone of Swift's modern concurrency model, designed to eliminate data races by enforcing rules at compile time. It acts as a 'marker' protocol, having no requirements of its own, but signaling to the compiler that a type's values can be safely copied and shared across concurrency boundaries (like between actors or tasks) without introducing shared mutable state.\n\n**Core Concept:**\nThe compiler verifies `Sendable` conformance whenever a value crosses a concurrency domain. If you attempt to pass a non-`Sendable` type to an actor or capture it in a concurrent `Task`, the compiler will issue a warning or error. This shifts the responsibility of thread safety from runtime discipline (e.g., manual locking) to compile-time verification.\n\n**Implicit Conformance:**\nSeveral types are implicitly `Sendable`:\n1.  **Value Types:** Structs and enums are `Sendable` if all their stored properties are also `Sendable`.\n2.  **Actors:** Actors inherently manage their own state and are thus `Sendable`.\n3.  **Immutable Classes:** A `final` class is `Sendable` if it has no mutable stored properties (`var`) and all its stored properties are of `Sendable` types.\n\n```swift\n// Implicitly Sendable struct because its properties are Sendable\nstruct UserProfile: Sendable {\n    let id: UUID\n    let name: String\n}\n\n// A class with mutable state is NOT Sendable by default.\nclass UserPreferences {\n    var isDarkMode: Bool = false // Mutable state\n}\n\nactor DataManager {\n    private var userCache: [UUID: UserProfile] = [:]\n\n    // OK: UserProfile is Sendable and can be passed across actor boundary.\n    func cache(_ profile: UserProfile) {\n        userCache[profile.id] = profile\n    }\n\n    // WARNING: Passing a non-Sendable type across actor boundary.\n    // Swift 6 will make this an error.\n    func apply(_ prefs: UserPreferences) {\n        // This is dangerous. Another thread could be modifying `prefs`\n        // at the same time, leading to a data race.\n        print(\"Applying preferences...\")\n    }\n}\n```\n\n**Common Pitfalls & Edge Cases:**\n- **Explicit Conformance:** You must explicitly mark a type `Sendable` if it meets the criteria but the compiler can't infer it (e.g., a `public` struct in a library whose properties are `internal`).\n- **`@unchecked Sendable`:** This is a powerful but dangerous escape hatch. You use it to tell the compiler to trust you that a type is safe, even if it doesn't meet the standard criteria. This is typically used for legacy classes that manage their own thread safety via internal locking (`NSLock`, serial queue). Misusing `@unchecked Sendable` can easily re-introduce data races the compiler was designed to prevent.\n\n**When to Use vs. Alternatives:**\nUse `Sendable` and the actor model for all new concurrent code in Swift. It provides the highest level of safety. The alternatives are older, manual synchronization primitives like `NSLock` or `DispatchQueue`. While still useful for interoperability or specific performance optimizations, they lack compiler verification, making them more error-prone. `Sendable` codifies the safety contract, allowing the toolchain to help you write correct concurrent code.",
      "code_example": null,
      "tags": [
        "concurrency",
        "swift",
        "actor",
        "sendable",
        "thread-safety",
        "data-race"
      ],
      "sources": [
        "https://www.objc.io/issues/2-concurrency/concurrency-apis-and-pitfalls/"
      ]
    },
    {
      "id": "concurrency_63f51f17b095",
      "front": "Explain how `@MainActor` solves UI-related data races compared to older GCD approaches. How does it differ from a custom global actor, and in what scenario would you define your own?",
      "back": "The `@MainActor` attribute is a global actor that ensures any code it annotates is executed on the main thread. This provides compile-time safety for UI updates, a significant improvement over the runtime-dependent `DispatchQueue.main.async` approach. With GCD, developers had to manually ensure UI code was dispatched to the main queue, a common source of bugs if forgotten. `@MainActor` lets the Swift compiler enforce this rule, preventing data races on UI components by flagging incorrect calls from other contexts as build errors.\n\nIt differs from a custom global actor in its purpose. `@MainActor` is a specific, system-provided actor tied to the main thread for UI operations. A custom global actor is a general-purpose tool you create to serialize access to any other shared mutable state across an application. You would define your own global actor to protect a resource like a database connection, a file logger, or a shared cache that needs to be accessed safely from multiple concurrent tasks.\n\n```swift\n// 1. A custom global actor for serializing database access\n@globalActor\nactor DatabaseActor {\n  static let shared = DatabaseActor()\n}\n\n// 2. ViewModel isolated to the MainActor\n@MainActor\nclass ProfileViewModel: ObservableObject {\n    @Published var username: String = \"Loading...\"\n\n    // This function can be called from any async context.\n    func fetchUser() async {\n        // Hop off the main actor to do background work\n        let user = await loadUserFromDB()\n        // Hop back to MainActor is implicit here due to class annotation.\n        // This UI update is now guaranteed to be on the main thread.\n        self.username = user.name\n    }\n\n    // 3. Isolate this specific function to our custom DatabaseActor\n    @DatabaseActor\n    private func loadUserFromDB() async -> User {\n        // This is now a protected context for database operations,\n        // preventing concurrent writes/reads from other parts of the app.\n        print(\"Current thread: \\(Thread.current)\") // Not the main thread\n        // ...database logic...\n        return User(name: \"Jane Doe\")\n    }\n}\nstruct User { let name: String }\n```\n\n**Common Pitfalls:**\n- **Over-isolation:** Annotating an entire complex class with `@MainActor` can cause performance issues if many of its methods don't need the main thread. Use `nonisolated` for functions that are thread-safe and don't touch UI to avoid unnecessary hops to the main thread.\n- **Blocking the UI:** `@MainActor` serializes tasks, it doesn't make them non-blocking. A long-running synchronous task or a long `await` on the main actor will still freeze the UI. Offload heavy work to a background `Task` or a different actor.",
      "code_example": null,
      "tags": [
        "concurrency",
        "actors",
        "swift-concurrency",
        "MainActor",
        "global-actors"
      ],
      "sources": [
        "https://www.objc.io/issues/2-concurrency/concurrency-apis-and-pitfalls/"
      ]
    },
    {
      "id": "concurrency_adf2fcd2570c",
      "front": "Explain how `withThrowingTaskGroup` manages child task lifecycle and error propagation. How does its cancellation behavior enforce the principles of structured concurrency?",
      "back": "A `TaskGroup` provides a structured way to run a dynamic number of child tasks concurrently. The `withThrowingTaskGroup` function creates a scope where the parent task is suspended until all child tasks complete. This enforces structured concurrency by ensuring the parent's scope cannot exit while child tasks are still running, preventing orphaned tasks.\n\nWhen a child task added via `group.addTask` throws an error, the group's behavior is critical:\n1.  The group immediately enters a 'cancelled' state.\n2.  It implicitly cancels all other running child tasks in the group.\n3.  It continues to wait for all child tasks to complete (either by finishing their work, acknowledging the cancellation, or throwing their own error).\n4.  Once all tasks are finished, the `withThrowingTaskGroup` call rethrows the *first* error that was thrown.\n\n```swift\n// Fetches multiple images concurrently, failing if any single download fails.\nfunc fetchThumbnails(for ids: [String]) async throws -> [UIImage] {\n    var thumbnails: [UIImage] = []\n    // The group's scope ensures we don't return until all tasks are done.\n    try await withThrowingTaskGroup(of: UIImage.self) { group in\n        for id in ids {\n            // Dynamically add a new child task for each ID.\n            group.addTask {\n                let url = URL(string: \"https://example.com/img/\\(id).jpg\")!\n                // This task must check for cancellation to be a good citizen.\n                // URLSessionDataTask handles this automatically.\n                try Task.checkCancellation()\n                let (data, _) = try await URLSession.shared.data(from: url)\n                guard let image = UIImage(data: data) else { \n                    throw URLError(.badServerResponse) \n                }\n                return image\n            }\n        }\n        \n        // As tasks complete, collect their results.\n        // If any task throws, this loop breaks and the error propagates.\n        for try await image in group {\n            thumbnails.append(image)\n        }\n    }\n    return thumbnails\n}\n```\n\n**Common Pitfalls:**\n- **Forgetting to drain the group:** Not iterating over all results (e.g., breaking a `for await` loop early without cancelling the group) can cause the task to remain suspended indefinitely.\n- **Ignoring Cancellation:** Child tasks performing long computations must manually check `Task.isCancelled` to halt work promptly when the group is cancelled. Network requests often handle this automatically.\n\n**Use vs. `async let`:**\n- **Task Group:** Ideal for a *dynamic* number of homogenous tasks (e.g., processing items in an array).\n- **`async let`:** Better for a *fixed*, small number of concurrent tasks, especially if they return different types. It offers a simpler, more declarative syntax.",
      "code_example": null,
      "tags": [
        "concurrency",
        "structured concurrency",
        "swift-concurrency",
        "async/await",
        "taskgroup"
      ],
      "sources": [
        "https://www.objc.io/issues/2-concurrency/concurrency-apis-and-pitfalls/"
      ]
    },
    {
      "id": "concurrency_0a59c109c99a",
      "front": "Explain how Swift's `actor` model enforces data race safety at compile time, contrasting it with traditional lock-based approaches. What is actor re-entrancy and why is it a crucial concept to understand?",
      "back": "### Core Concept\n\nSwift's `actor` is a reference type that provides a synchronization mechanism to protect its mutable state from concurrent access, eliminating data races. This is achieved through **actor isolation**: the compiler enforces that all access to an actor's mutable properties and methods from the outside must be asynchronous (`await`). This effectively places incoming calls into a conceptual 'mailbox', which the actor processes serially, one at a time. This shifts the burden of thread safety from the developer (manual locking) to the compiler (static analysis), making concurrent code safer by default.\n\nThis contrasts sharply with traditional locks (`NSLock`, `DispatchQueue`), where developers must manually acquire and release locks around critical sections. This manual approach is error-prone, leading to issues like forgetting to unlock, deadlocks, and performance bottlenecks.\n\n**Actor Re-entrancy** is a key feature. When an actor-isolated function suspends (hits an `await`), it gives up its thread. The actor is now free to process other waiting tasks from its mailbox. When the awaited operation completes, the original function is rescheduled to continue. This prevents deadlocks (e.g., actor A calls actor B, which calls back to A) and improves throughput. However, it means the actor's state can be mutated by other tasks during a suspension point. A senior developer must always assume state has changed across any `await` and re-validate it.\n\n### Practical Code Example\n```swift\nactor TemperatureLogger {\n    private var measurements: [Double] = []\n    var high: Double = -Double.infinity\n\n    func log(temperature: Double) {\n        measurements.append(temperature)\n        if temperature > high {\n            high = temperature // Safe direct mutation\n        }\n    }\n\n    // This method has a suspension point (`await`)\n    func processAndUpload() async throws -> Double {\n        // Read current state before suspension\n        let currentHigh = self.high\n        print(\"Current high before await: \\(currentHigh)\")\n\n        // 'await' is a suspension point. Other tasks can run on this actor now.\n        // For example, another thread could call `log(temperature: 100)` here.\n        let serverResponse = await APIService.upload(data: measurements)\n        \n        // CRITICAL: State might have changed. Must re-read from self.\n        // Using `currentHigh` here would be a bug if state changed.\n        print(\"New high after await: \\(self.high)\")\n        return self.high // Return the potentially updated value\n    }\n}\n```\n### Common Pitfalls\n- **Stale State Across `await`:** The most common mistake is reading state, awaiting an async call, and then acting on the *old*, cached state variable. You must re-read the actor's state (`self.property`) after a suspension point if your logic depends on its latest value.\n- **Blocking Calls:** Performing long, synchronous, blocking work inside an actor method will block the entire actor, preventing it from processing other tasks and negating its concurrency benefits.\n- **Misusing `nonisolated`:** Using `nonisolated` on a method that subtly mutates state (e.g., through a non-isolated class instance it holds) breaks the actor's safety guarantees.\n\n### When to Use vs. Alternatives\n- **Use Actors for:** Encapsulating and protecting the mutable state of an object, like a cache, data manager, or repository. They are the modern, safe default for isolated state in Swift.\n- **Alternatives:**\n  - **Serial `DispatchQueue`:** A classic GCD approach. Provides serial execution but lacks the compiler safety and strong coupling of state-to-protection that actors provide.\n  - **Locks (`os_unfair_lock`)**: For performance-critical, fine-grained control over very small critical sections. They are much more dangerous and should be used sparingly due to the risk of deadlocks and priority inversion.",
      "code_example": null,
      "tags": [
        "concurrency",
        "actors",
        "swift-concurrency",
        "data-races",
        "re-entrancy"
      ],
      "sources": [
        "https://www.objc.io/issues/2-concurrency/concurrency-apis-and-pitfalls/"
      ]
    },
    {
      "id": "concurrency_b2a458c2caac",
      "front": "Describe how to use `AsyncStream` to adapt a non-async, callback-based API to the modern `async/await` world. What are the critical responsibilities when managing its continuation?",
      "back": "`AsyncStream` is a concrete type that conforms to the `AsyncSequence` protocol. Its primary role is to act as a bridge, adapting existing, non-structured asynchronous code\u2014like delegate patterns or callback closures\u2014into a modern `AsyncSequence` that can be iterated over with a `for await` loop.\n\n**Core Concept:**\nYou initialize an `AsyncStream` with a closure that provides a `continuation`. This continuation is your tool to communicate with the stream from your non-async code. The key responsibilities are:\n1.  **Yielding Values:** Call `continuation.yield(value)` whenever the legacy API produces a new value.\n2.  **Terminating the Stream:** Call `continuation.finish()` when the source of events is exhausted or an unrecoverable error occurs. This is crucial to allow the `for await` loop to terminate gracefully.\n3.  **Resource Management:** Use the `onTermination` closure to clean up resources (e.g., stop a timer, deregister a delegate). This closure is called when the stream is finished or when its consumer is cancelled.\n4.  **Handling Backpressure:** Be mindful of the buffering policy. If the producer (your callback) yields values faster than the consumer (the `for await` loop) consumes them, the buffer can grow. The default is `.unbounded`, which can lead to memory issues. Consider using `.bufferingNewest(n)` or `.bufferingOldest(n)`.\n\n**Practical Code Example (Adapting a Location Manager Delegate):**\n```swift\n// Hypothetical legacy location manager\nclass LocationManager {\n    var onLocationUpdate: ((CLLocation) -> Void)?\n    var onFinish: (() -> Void)?\n    func start() { /* Simulates starting updates */ }\n    func stop() { /* Simulates stopping updates */ }\n}\n\nfunc locations() -> AsyncStream<CLLocation> {\n    let manager = LocationManager()\n\n    return AsyncStream { continuation in\n        // Set the callback to yield values to the stream\n        manager.onLocationUpdate = { location in\n            continuation.yield(location)\n        }\n\n        // Set the completion callback to finish the stream\n        manager.onFinish = {\n            continuation.finish()\n        }\n\n        // Define cleanup logic for when the stream terminates\n        continuation.onTermination = { @Sendable _ in\n            print(\"Stream terminated. Stopping location manager.\")\n            manager.stop()\n        }\n\n        // Start the underlying work\n        manager.start()\n    }\n}\n\n// Usage:\nTask {\n    for await location in locations() {\n        print(\"New location: \\(location.coordinate)\")\n    }\n    print(\"Finished receiving location updates.\")\n}\n```\n\n**Common Pitfalls:**\n*   **Forgetting `finish()`:** The `for await` loop will hang indefinitely, leaking resources.\n*   **Leaking the Continuation:** The continuation must *never* escape the `AsyncStream` initializer closure. Storing it in a property is a serious programming error.\n*   **Mismanaging Termination:** Calling `yield()` after `finish()` will cause a runtime crash.\n*   **Ignoring Cancellation:** The `onTermination` closure is your chance to react to task cancellation and stop expensive work in the underlying legacy API.",
      "code_example": null,
      "tags": [
        "concurrency",
        "swift-concurrency",
        "async-await",
        "asyncsequence",
        "asyncstream"
      ],
      "sources": [
        "https://www.objc.io/issues/2-concurrency/concurrency-apis-and-pitfalls/",
        "https://www.objc.io/issues/2-concurrency/common-background-practices/"
      ]
    },
    {
      "id": "concurrency_dbfc3f91d97e",
      "front": "Compare Actors, Serial Queues (GCD), and Locks for preventing data races. Describe the trade-offs of each and provide a scenario where one is clearly superior.",
      "back": "Data races occur when multiple threads access shared mutable state without synchronization, leading to unpredictable behavior. Swift provides several mechanisms to prevent this, each with distinct trade-offs.\n\n**1. Actors**\n- **Core Concept:** An actor is a reference type that protects its state from concurrent access. It creates a 'synchronization island', ensuring that only one task can access its mutable state at a time. The Swift compiler enforces this by requiring external access to an actor's properties and methods to be asynchronous (using `await`), which serializes access through the actor's mailbox.\n- **When to Use:** The default choice for new code in a Swift Concurrency environment. Ideal for encapsulating the state and logic of an object, like a view model, repository, or service.\n\n**2. Serial Queues (GCD)**\n- **Core Concept:** A classic approach using Grand Central Dispatch. By dispatching all read/write operations to a shared resource onto a single serial `DispatchQueue`, you guarantee that operations are executed one at a time, in order. Writes are often performed with `sync` or `async` calls, while reads can use the same pattern. For more complex scenarios, a concurrent queue with a barrier flag for write operations is a powerful pattern (Readers-Writer lock).\n- **When to Use:** Excellent for integrating with older, non-async codebases, or when you need to synchronize access to a resource not neatly encapsulated by an object (e.g., a file handle). It offers more manual control over execution priority (QoS).\n\n**3. Locks (`NSLock`, `os_unfair_lock`)**\n- **Core Concept:** A low-level, primitive synchronization mechanism. A thread must acquire a lock before entering a 'critical section' (code accessing shared state) and release it upon exit. This manually enforces mutual exclusion. `os_unfair_lock` is the modern, high-performance choice, replacing the older `OSSpinLock`.\n- **When to Use:** In performance-critical code where the overhead of dispatching to a queue or an actor's mailbox is unacceptable and the critical section is very short. This is an expert-level tool.\n\n**Code Example (Actor is the modern approach):**\n```swift\n// Actor provides compile-time safety\nactor BalanceManager {\n    private var balance: Decimal = 1000.0\n\n    func withdraw(amount: Decimal) -> Bool {\n        if balance >= amount {\n            balance -= amount\n            return true\n        }\n        return false\n    }\n}\n\n// A Serial Queue provides runtime safety\nclass BalanceManager_GCD {\n    private let syncQueue = DispatchQueue(label: \"com.balance.syncqueue\")\n    private var balance: Decimal = 1000.0\n\n    func withdraw(amount: Decimal) -> Bool {\n        syncQueue.sync { // .sync ensures exclusive access and returns the value\n            if balance >= amount {\n                balance -= amount\n                return true\n            }\n            return false\n        }\n    }\n}\n```\n\n**Pitfalls & Trade-offs:**\n- **Actors:** Can introduce suspension points with `await`, and passing non-`Sendable` types can create data races if not handled carefully (though Swift 6 aims to make this fully safe).\n- **Serial Queues:** No compiler protection; correctness relies on developer discipline. Prone to deadlocks if you call `sync` on a queue from a task already running on that same queue.\n- **Locks:** Most dangerous. Easy to forget to unlock, leading to deadlocks. Can cause priority inversion issues. They are not composable and don't integrate with Swift's structured concurrency.",
      "code_example": null,
      "tags": [
        "concurrency",
        "swift-concurrency",
        "actors",
        "gcd",
        "data-race",
        "locks"
      ],
      "sources": [
        "https://www.objc.io/issues/2-concurrency/concurrency-apis-and-pitfalls/"
      ]
    },
    {
      "id": "concurrency_ef63c6d3be70",
      "front": "How does Swift's Structured Concurrency improve upon unstructured models like GCD by managing task lifetime, cancellation, and error propagation? Explain the concept of a 'Task Tree'.",
      "back": "Structured Concurrency introduces a paradigm where concurrent tasks are organized into a hierarchy, often called a 'Task Tree.' This structure provides explicit scopes and lifetimes for tasks. Unlike 'unstructured' models like GCD where dispatched blocks run independently, a structured task has a clear parent-child relationship.\n\nThis hierarchy provides three critical guarantees:\n1.  **Lifetime Management:** A parent task cannot complete until all of its child tasks have finished. This eliminates 'leaked' tasks that might continue running after their results are no longer needed, a common bug with fire-and-forget GCD calls.\n2.  **Cancellation Propagation:** When a parent task is cancelled, the cancellation is automatically propagated to all its children. This drastically simplifies cancellation logic compared to manually managing cancellation flags or `NSOperation` states.\n3.  **Error Propagation:** If a child task throws an error, it is immediately propagated up to the parent, which can then handle it. This avoids complex nested completion handlers with `Result` types.\n\n**Code Example:**\n```swift\n// Fetches user profile data by running two network calls in parallel.\nfunc fetchUserProfile(for id: String) async throws -> UserProfile {\n    print(\"Parent task started for user \\(id)\")\n\n    // 'async let' creates child tasks that run concurrently.\n    // They are \"children\" of the `fetchUserProfile` task.\n    async let user = fetchUserDetails(id)\n    async let friends = fetchUserFriends(id)\n\n    // The function implicitly awaits both child tasks here before returning.\n    // If 'fetchUserFriends' throws, the 'user' task is cancelled.\n    // If the parent `fetchUserProfile` task is cancelled, both children are cancelled.\n    let profile = try await UserProfile(user: user, friends: friends)\n    \n    print(\"Parent task finished, all children completed.\")\n    return profile\n}\n```\n\n**Common Pitfalls:**\n- **Accidental Unstructured Tasks:** Using `Task { ... }` inside an `async` function creates a *new, detached, top-level task*. It breaks the parent-child relationship, losing all structured benefits. Use `async let` or `TaskGroup` to maintain structure.\n- **Ignoring Cancellation:** Cancellation is cooperative. Your long-running child task must periodically check for it with `try Task.checkCancellation()` or `Task.isCancelled` and stop its work. Without this check, the task will run to completion despite being 'cancelled.'\n\n**When to Use vs. Alternatives:**\n- **Structured Concurrency (`async let`, `TaskGroup`):** The default choice for all new concurrent code in Swift. It's safer and more readable. Use `async let` for a fixed number of parallel tasks and `TaskGroup` for a dynamic number.\n- **Unstructured `Task { ... }`:** Use deliberately for tasks that must outlive the current scope, like a background sync started from a view that might be dismissed. You are responsible for managing its lifetime.\n- **GCD/`OperationQueue`:** Still necessary for legacy code, Objective-C interoperability, or for specific features like `NSOperation` dependencies.",
      "code_example": null,
      "tags": [
        "concurrency",
        "swift",
        "structured-concurrency",
        "async-await"
      ],
      "sources": [
        "https://www.objc.io/issues/2-concurrency/concurrency-apis-and-pitfalls/"
      ]
    }
  ]
}