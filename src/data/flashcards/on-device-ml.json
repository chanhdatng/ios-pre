{
  "topic": "on-device-ml",
  "title": "On-Device AI/ML Integration (Core ML)",
  "description": "Apple's privacy-first approach to machine learning - rapidly growing interview topic",
  "cards": [
    {
      "id": "ml_001",
      "front": "Explain the trade-offs between on-device ML (Core ML) and cloud-based ML. Design a feature for a fitness app that adapts workouts based on performance.",
      "back": "**On-Device vs Cloud ML Trade-offs:**\n\n| Factor | On-Device (Core ML) | Cloud ML |\n|--------|---------------------|----------|\n| **Latency** | ~10-100ms | 200-2000ms |\n| **Privacy** | Data stays on device | Data sent to server |\n| **Offline** | Works offline | Requires connection |\n| **Model size** | Limited (~100MB typical) | Unlimited |\n| **Model updates** | App update required | Instant |\n| **Cost** | Free (user's device) | Per-inference cost |\n| **Accuracy** | Limited by device | Can use larger models |\n\n**Fitness App: Adaptive Workout Feature**\n\n```swift\n// MARK: - On-Device Recommendation Engine\nimport CoreML\nimport CreateML\n\nstruct WorkoutRecommender {\n    private let model: WorkoutAdaptationModel\n    \n    init() throws {\n        let config = MLModelConfiguration()\n        config.computeUnits = .cpuAndNeuralEngine  // Use Neural Engine\n        model = try WorkoutAdaptationModel(configuration: config)\n    }\n    \n    func recommendNextWorkout(userProfile: UserProfile, recentPerformance: [WorkoutResult]) -> WorkoutPlan {\n        // Feature extraction\n        let features = extractFeatures(profile: userProfile, performance: recentPerformance)\n        \n        // On-device inference\n        let prediction = try! model.prediction(\n            avgHeartRate: features.avgHeartRate,\n            completionRate: features.completionRate,\n            recoveryTime: features.recoveryTime,\n            fitnessLevel: features.fitnessLevel,\n            preferredIntensity: features.preferredIntensity\n        )\n        \n        return WorkoutPlan(\n            intensity: prediction.recommendedIntensity,\n            duration: prediction.recommendedDuration,\n            exercises: prediction.exerciseTypes\n        )\n    }\n}\n\n// MARK: - Hybrid Approach (Best of Both)\nclass AdaptiveWorkoutEngine {\n    private let localModel: WorkoutRecommender\n    private let cloudAPI: CloudMLService\n    \n    func getWorkoutRecommendation(user: User) async -> WorkoutPlan {\n        // 1. Always start with on-device (fast, private)\n        let localRecommendation = localModel.recommendNextWorkout(\n            userProfile: user.profile,\n            recentPerformance: user.recentWorkouts\n        )\n        \n        // 2. Enhance with cloud if connected and user consents\n        if NetworkMonitor.isConnected && user.hasCloudMLConsent {\n            do {\n                let cloudEnhancement = try await cloudAPI.enhanceRecommendation(\n                    base: localRecommendation,\n                    anonymizedProfile: user.profile.anonymized\n                )\n                return merge(local: localRecommendation, cloud: cloudEnhancement)\n            } catch {\n                // Graceful fallback to local\n                return localRecommendation\n            }\n        }\n        \n        return localRecommendation\n    }\n}\n```\n\n**Architecture:**\n```\n┌─────────────────────────────────────────┐\n│             Fitness App                  │\n├─────────────────────────────────────────┤\n│  On-Device ML (Always)                  │\n│  • Basic recommendations                │\n│  • Performance tracking                 │\n│  • Works offline                        │\n├─────────────────────────────────────────┤\n│  Cloud ML (Optional, with consent)      │\n│  • Enhanced personalization             │\n│  • Cross-user patterns                  │\n│  • Latest model updates                 │\n└─────────────────────────────────────────┘\n```\n\n**Recommendation:** On-device first for privacy and offline. Cloud for optional enhancements with explicit consent.",
      "tags": ["coreml", "cloud-ml", "privacy", "fitness", "hybrid"],
      "sources": ["https://developer.apple.com/documentation/coreml"],
      "summary": "On-device: fast, private, offline, limited size. Cloud: larger models, instant updates, requires connection. Use hybrid: local first, cloud enhancement with consent."
    },
    {
      "id": "ml_002",
      "front": "You want to add intelligent recommendations to a shopping app. Using Core ML with a pre-trained model, how would you integrate and optimize for on-device execution?",
      "back": "**Core ML Integration for Product Recommendations:**\n\n**Step 1: Convert/Obtain Model**\n```bash\n# Convert from PyTorch/TensorFlow\npython -m coremltools.converters.convert \\\n    --model recommendation_model.pt \\\n    --output ProductRecommender.mlpackage\n\n# Or use Create ML for tabular data\n```\n\n**Step 2: Optimize Model**\n```swift\nimport CoreML\n\n// Quantize for smaller size and faster inference\nlet config = MLModelConfiguration()\nconfig.computeUnits = .all  // CPU + GPU + Neural Engine\n\n// Model compression options\n// 16-bit: 50% size reduction, minimal accuracy loss\n// 8-bit: 75% size reduction, some accuracy loss\n```\n\n**Step 3: Integration**\n```swift\nclass ProductRecommendationEngine {\n    private let model: ProductRecommender\n    private let featureExtractor: FeatureExtractor\n    private let cache = NSCache<NSString, RecommendationResult>()\n    \n    init() throws {\n        let config = MLModelConfiguration()\n        config.computeUnits = .cpuAndNeuralEngine\n        \n        // Load model asynchronously to not block main thread\n        model = try ProductRecommender(configuration: config)\n    }\n    \n    func getRecommendations(for user: User, context: BrowsingContext) async throws -> [Product] {\n        // Check cache first\n        let cacheKey = \"\\(user.id)_\\(context.hashValue)\" as NSString\n        if let cached = cache.object(forKey: cacheKey) {\n            return cached.products\n        }\n        \n        // Extract features\n        let features = featureExtractor.extract(\n            viewHistory: user.viewHistory,\n            purchaseHistory: user.purchaseHistory,\n            currentCategory: context.category,\n            timeOfDay: context.timeOfDay,\n            dayOfWeek: context.dayOfWeek\n        )\n        \n        // Run inference on background thread\n        let predictions = try await Task.detached(priority: .userInitiated) {\n            try self.model.prediction(\n                userEmbedding: features.userEmbedding,\n                contextEmbedding: features.contextEmbedding,\n                categoryOneHot: features.categoryOneHot\n            )\n        }.value\n        \n        // Convert predictions to products\n        let productIds = predictions.recommendedProductIds\n        let products = try await productStore.fetch(ids: productIds)\n        \n        // Cache results\n        cache.setObject(RecommendationResult(products: products), forKey: cacheKey)\n        \n        return products\n    }\n}\n```\n\n**Step 4: Batch Processing for Feed**\n```swift\nextension ProductRecommendationEngine {\n    func precomputeRecommendations(for user: User) async {\n        // Background task to precompute common contexts\n        let contexts: [BrowsingContext] = [\n            .home, .categoryBrowsing, .checkout, .postPurchase\n        ]\n        \n        await withTaskGroup(of: Void.self) { group in\n            for context in contexts {\n                group.addTask {\n                    _ = try? await self.getRecommendations(for: user, context: context)\n                }\n            }\n        }\n    }\n}\n```\n\n**Step 5: Performance Monitoring**\n```swift\nclass MLPerformanceMonitor {\n    func measureInference<T>(model: String, operation: () throws -> T) rethrows -> T {\n        let start = CFAbsoluteTimeGetCurrent()\n        let result = try operation()\n        let duration = CFAbsoluteTimeGetCurrent() - start\n        \n        Analytics.track(\"ml_inference\", properties: [\n            \"model\": model,\n            \"duration_ms\": duration * 1000,\n            \"device\": UIDevice.current.model\n        ])\n        \n        return result\n    }\n}\n```\n\n**Optimization Checklist:**\n- [ ] Use Neural Engine (`computeUnits = .cpuAndNeuralEngine`)\n- [ ] Quantize model (16-bit or 8-bit)\n- [ ] Cache predictions\n- [ ] Run inference off main thread\n- [ ] Batch requests when possible\n- [ ] Precompute for common scenarios\n- [ ] Monitor inference latency",
      "tags": ["coreml", "recommendations", "optimization", "shopping", "inference"],
      "sources": ["https://developer.apple.com/documentation/coreml/integrating_a_core_ml_model_into_your_app"],
      "summary": "Convert model → optimize (quantize, Neural Engine) → cache predictions → run off main thread → batch when possible → monitor performance."
    },
    {
      "id": "ml_003",
      "front": "Apple's Foundation Models framework allows on-device LLMs. Design a customer support feature for a banking app that can answer questions using local LLMs without server round-trips.",
      "back": "**On-Device LLM Customer Support:**\n\n**Architecture:**\n```\n┌─────────────────────────────────────────┐\n│         Banking App                      │\n├─────────────────────────────────────────┤\n│  Foundation Models (On-Device)          │\n│  • FAQ answering                        │\n│  • Transaction explanations             │\n│  • Basic account guidance               │\n├─────────────────────────────────────────┤\n│  Fallback: Human Agent                  │\n│  • Complex issues                       │\n│  • Disputes                             │\n│  • Account changes                      │\n└─────────────────────────────────────────┘\n```\n\n**Implementation with Foundation Models:**\n```swift\nimport Foundation\nimport FoundationModels  // iOS 26+\n\nclass BankingSupportAssistant {\n    private let session: LanguageModelSession\n    private let knowledgeBase: BankingKnowledgeBase\n    \n    init() async throws {\n        // Initialize on-device LLM session\n        let config = LanguageModelConfiguration(\n            model: .foundationModel,\n            systemPrompt: \"\"\"\n            You are a helpful banking assistant for SecureBank.\n            You can answer questions about:\n            - Account balances and transactions\n            - Fee explanations\n            - Basic banking procedures\n            - Security best practices\n            \n            Rules:\n            - Never reveal sensitive account details\n            - For complex issues, suggest contacting support\n            - Be concise and professional\n            \"\"\"\n        )\n        session = try await LanguageModelSession(configuration: config)\n    }\n    \n    func answerQuestion(_ question: String, context: UserContext) async throws -> SupportResponse {\n        // 1. Classify question type\n        let classification = classifyQuestion(question)\n        \n        // 2. Handle based on classification\n        switch classification {\n        case .faq:\n            return try await answerFAQ(question)\n            \n        case .transactionQuery:\n            return try await explainTransaction(question, context: context)\n            \n        case .sensitive, .accountChange:\n            return .escalateToHuman(reason: \"This request requires human verification\")\n            \n        case .general:\n            return try await generateResponse(question, context: context)\n        }\n    }\n    \n    private func answerFAQ(_ question: String) async throws -> SupportResponse {\n        // Retrieve relevant FAQ context\n        let relevantFAQs = knowledgeBase.search(query: question, limit: 3)\n        \n        let prompt = \"\"\"\n        Based on these FAQs, answer the user's question:\n        \n        FAQs:\n        \\(relevantFAQs.map { \"Q: \\($0.question)\\nA: \\($0.answer)\" }.joined(separator: \"\\n\\n\"))\n        \n        User question: \\(question)\n        \n        Provide a helpful, concise answer:\n        \"\"\"\n        \n        let response = try await session.generate(prompt: prompt)\n        return .answer(response.text)\n    }\n    \n    private func explainTransaction(_ question: String, context: UserContext) async throws -> SupportResponse {\n        // Get recent transactions (already on device)\n        let transactions = context.recentTransactions\n        \n        let prompt = \"\"\"\n        The user is asking about their transactions:\n        \n        Recent transactions:\n        \\(transactions.map { \"\\($0.date): \\($0.merchant) - \\($0.amount)\" }.joined(separator: \"\\n\"))\n        \n        Question: \\(question)\n        \n        Explain clearly without revealing full account numbers:\n        \"\"\"\n        \n        let response = try await session.generate(prompt: prompt)\n        return .answer(response.text)\n    }\n}\n```\n\n**Safety & Guardrails:**\n```swift\nextension BankingSupportAssistant {\n    func classifyQuestion(_ question: String) -> QuestionType {\n        // On-device classification for safety\n        let sensitivePatterns = [\n            \"transfer\", \"send money\", \"change password\",\n            \"close account\", \"dispute\", \"fraud\"\n        ]\n        \n        let lowercased = question.lowercased()\n        \n        for pattern in sensitivePatterns {\n            if lowercased.contains(pattern) {\n                return .sensitive\n            }\n        }\n        \n        return .general\n    }\n    \n    func validateResponse(_ response: String) -> Bool {\n        // Ensure response doesn't contain sensitive data\n        let patterns = [\n            \"\\\\b\\\\d{4}[- ]?\\\\d{4}[- ]?\\\\d{4}[- ]?\\\\d{4}\\\\b\",  // Card numbers\n            \"\\\\b\\\\d{3}-\\\\d{2}-\\\\d{4}\\\\b\",  // SSN\n            \"\\\\b\\\\d{9,12}\\\\b\"  // Account numbers\n        ]\n        \n        for pattern in patterns {\n            if response.range(of: pattern, options: .regularExpression) != nil {\n                return false  // Block response\n            }\n        }\n        return true\n    }\n}\n```\n\n**UI Integration:**\n```swift\nstruct SupportChatView: View {\n    @StateObject var assistant = BankingSupportViewModel()\n    @State private var userInput = \"\"\n    \n    var body: some View {\n        VStack {\n            ScrollView {\n                ForEach(assistant.messages) { message in\n                    MessageBubble(message: message)\n                }\n            }\n            \n            HStack {\n                TextField(\"Ask a question...\", text: $userInput)\n                Button(\"Send\") {\n                    Task {\n                        await assistant.send(userInput)\n                        userInput = \"\"\n                    }\n                }\n            }\n        }\n        .overlay {\n            if assistant.isProcessing {\n                ProgressView(\"Thinking...\")\n            }\n        }\n    }\n}\n```\n\n**Key Benefits:**\n- **Privacy:** Sensitive banking questions never leave device\n- **Speed:** <100ms response time\n- **Offline:** Works without internet\n- **Cost:** No per-query API costs",
      "tags": ["foundation-models", "llm", "on-device", "banking", "customer-support"],
      "sources": ["https://developer.apple.com/machine-learning/"],
      "summary": "Use Foundation Models for FAQ, transaction explanations. Classify questions for safety. Escalate sensitive requests to humans. Validate responses for PII."
    },
    {
      "id": "ml_004",
      "front": "Core ML models have size constraints. How do you choose between a smaller, faster model vs. a larger, more accurate one? What metrics matter for production?",
      "back": "**Model Size vs. Accuracy Trade-offs:**\n\n**Size Constraints:**\n- App Store limit: 4GB total app size\n- Practical limit: <200MB for model (user experience)\n- Neural Engine optimized: <100MB\n- On-demand resources: Can download larger models\n\n**Decision Framework:**\n\n```swift\n// Model Selection Matrix\nenum ModelTier {\n    case tiny    // <5MB, ~85% accuracy, <10ms\n    case small   // <20MB, ~90% accuracy, <50ms\n    case medium  // <100MB, ~95% accuracy, <100ms\n    case large   // >100MB, ~98% accuracy, <500ms\n    \n    static func select(for useCase: UseCase) -> ModelTier {\n        switch useCase {\n        case .realTimeCamera:\n            return .tiny  // Must be fast\n        case .photoEnhancement:\n            return .medium  // Quality matters, can wait\n        case .documentOCR:\n            return .small  // Balance\n        case .medicalDiagnosis:\n            return .large  // Accuracy critical\n        }\n    }\n}\n```\n\n**Key Metrics for Production:**\n\n```swift\nstruct ModelMetrics {\n    // Size metrics\n    let modelSizeMB: Double\n    let memoryUsageMB: Double\n    \n    // Performance metrics\n    let inferenceTimeP50ms: Double  // Median\n    let inferenceTimeP95ms: Double  // 95th percentile\n    let inferenceTimeP99ms: Double  // Worst case\n    \n    // Accuracy metrics\n    let accuracy: Double       // Overall accuracy\n    let precision: Double      // True positives / predicted positives\n    let recall: Double         // True positives / actual positives\n    let f1Score: Double        // Harmonic mean of precision/recall\n    \n    // Production metrics\n    let batteryImpact: BatteryImpact  // Low/Medium/High\n    let thermalImpact: ThermalImpact\n    let crashRate: Double      // Inference failures\n}\n\n// Monitoring in production\nclass ModelMonitor {\n    func trackInference(model: String, result: InferenceResult) {\n        Analytics.track(\"ml_inference\", properties: [\n            \"model\": model,\n            \"duration_ms\": result.durationMs,\n            \"confidence\": result.confidence,\n            \"device_model\": UIDevice.current.model,\n            \"ios_version\": UIDevice.current.systemVersion,\n            \"battery_level\": UIDevice.current.batteryLevel,\n            \"thermal_state\": ProcessInfo.processInfo.thermalState.rawValue\n        ])\n    }\n}\n```\n\n**Optimization Techniques:**\n\n```swift\n// 1. Quantization\n// Full precision (32-bit): 100MB → 16-bit: 50MB → 8-bit: 25MB\nlet config = MLModelConfiguration()\nconfig.computeUnits = .cpuAndNeuralEngine\n\n// 2. Pruning (remove low-impact weights)\n// Reduces size by 50-90% with minimal accuracy loss\n\n// 3. Knowledge Distillation\n// Train small \"student\" model from large \"teacher\"\n\n// 4. On-Demand Resources\nfunc downloadModelIfNeeded() async throws {\n    let request = NSBundleResourceRequest(tags: [\"large-ml-model\"])\n    try await request.beginAccessingResources()\n    // Model now available\n}\n```\n\n**A/B Testing Models:**\n\n```swift\nclass ModelABTest {\n    func selectModel(for user: User) -> MLModel {\n        // 50% get new, more accurate model\n        if user.id.hashValue % 2 == 0 {\n            Analytics.setUserProperty(\"model_variant\", value: \"v2_accurate\")\n            return try! AccurateModel()\n        } else {\n            Analytics.setUserProperty(\"model_variant\", value: \"v1_fast\")\n            return try! FastModel()\n        }\n    }\n    \n    func compareMetrics() {\n        // Compare in analytics:\n        // - User engagement\n        // - Task completion rate\n        // - Battery complaints\n        // - Inference success rate\n    }\n}\n```\n\n**Decision Checklist:**\n- [ ] Real-time requirement? → Smaller model\n- [ ] Accuracy critical (medical, financial)? → Larger model\n- [ ] Offline required? → Must fit on device\n- [ ] Background processing? → Can use larger model\n- [ ] Target devices include older iPhones? → Smaller model\n- [ ] Can use on-demand resources? → Larger model OK",
      "tags": ["coreml", "model-optimization", "quantization", "metrics", "production"],
      "sources": ["https://developer.apple.com/documentation/coreml/reducing_the_size_of_your_core_ml_app"],
      "summary": "Balance: size (<100MB ideal), latency (P95 <100ms), accuracy (domain-dependent). Use quantization (16/8-bit), pruning. A/B test models. Monitor thermal/battery impact."
    },
    {
      "id": "ml_005",
      "front": "Design a feature that personalizes app UI based on user behavior using on-device ML. How would you train/update the model? How would you A/B test?",
      "back": "**On-Device UI Personalization:**\n\n**Feature: Adaptive Home Screen**\n```swift\n// Predict which features user will tap next\nstruct UIPersonalizer {\n    private var model: PersonalizationModel\n    private let trainer: OnDeviceTrainer\n    \n    func predictNextAction(context: UserContext) -> [FeatureRanking] {\n        let features = extractFeatures(context)\n        let predictions = try! model.prediction(\n            timeOfDay: features.timeOfDay,\n            dayOfWeek: features.dayOfWeek,\n            recentActions: features.recentActions,\n            sessionDuration: features.sessionDuration\n        )\n        \n        return FeatureRanking.from(predictions.featureScores)\n    }\n    \n    // Personalized home screen\n    func getHomeLayout(for user: User) -> [HomeSection] {\n        let rankings = predictNextAction(context: user.currentContext)\n        \n        return [\n            HomeSection(title: \"For You\", items: rankings.prefix(4).map { $0.feature }),\n            HomeSection(title: \"Recent\", items: user.recentlyUsed),\n            HomeSection(title: \"Discover\", items: trending)\n        ]\n    }\n}\n```\n\n**On-Device Training with Create ML:**\n```swift\nimport CreateML\n\nclass OnDeviceTrainer {\n    func trainPersonalizationModel(from interactions: [UserInteraction]) async throws -> MLModel {\n        // Prepare training data\n        let trainingData = interactions.map { interaction -> [String: Any] in\n            [\n                \"timeOfDay\": interaction.timeOfDay,\n                \"dayOfWeek\": interaction.dayOfWeek,\n                \"previousAction\": interaction.previousAction,\n                \"targetAction\": interaction.action  // Label\n            ]\n        }\n        \n        let dataFrame = try DataFrame(dictionaryLiteral: trainingData)\n        \n        // Train classifier\n        let model = try MLClassifier(\n            trainingData: dataFrame,\n            targetColumn: \"targetAction\"\n        )\n        \n        // Save locally\n        let modelURL = getModelPath()\n        try model.write(to: modelURL)\n        \n        return try MLModel(contentsOf: modelURL)\n    }\n    \n    // Incremental learning\n    func updateModel(with newInteractions: [UserInteraction]) async throws {\n        // Retrain weekly with recent data\n        let recentData = loadRecentInteractions(days: 30)\n        let updatedModel = try await trainPersonalizationModel(from: recentData)\n        \n        // Validate before deploying\n        let accuracy = evaluate(updatedModel, on: validationSet)\n        if accuracy > 0.7 {  // Threshold\n            self.model = updatedModel\n        }\n    }\n}\n```\n\n**A/B Testing Framework:**\n```swift\nclass PersonalizationABTest {\n    enum Variant: String {\n        case control = \"no_personalization\"\n        case mlPersonalized = \"ml_personalization\"\n        case rulesBased = \"rules_personalization\"\n    }\n    \n    func assignVariant(userId: String) -> Variant {\n        // Deterministic assignment based on user ID\n        let hash = userId.hashValue\n        switch abs(hash) % 3 {\n        case 0: return .control\n        case 1: return .mlPersonalized\n        case 2: return .rulesBased\n        default: return .control\n        }\n    }\n    \n    func getHomeLayout(for user: User) -> [HomeSection] {\n        let variant = assignVariant(userId: user.id)\n        \n        // Track assignment\n        Analytics.setUserProperty(\"personalization_variant\", value: variant.rawValue)\n        \n        switch variant {\n        case .control:\n            return defaultLayout()\n        case .mlPersonalized:\n            return mlPersonalizer.getHomeLayout(for: user)\n        case .rulesBased:\n            return rulesBasedLayout(for: user)\n        }\n    }\n    \n    func trackEngagement(action: String, user: User) {\n        Analytics.track(\"feature_tap\", properties: [\n            \"action\": action,\n            \"variant\": assignVariant(userId: user.id).rawValue,\n            \"position\": getPosition(action, in: currentLayout),\n            \"time_to_tap_ms\": timeSinceScreenLoad\n        ])\n    }\n}\n\n// Metrics to compare\nstruct ABTestMetrics {\n    let variant: String\n    let engagementRate: Double      // Taps / impressions\n    let timeToFirstAction: Double   // Seconds\n    let sessionDuration: Double     // Minutes\n    let featureDiscovery: Double    // Unique features used\n    let returnRate: Double          // Users returning next day\n}\n```\n\n**Privacy-Preserving Training:**\n```swift\nclass PrivatePersonalization {\n    // All training happens on-device\n    // No user data sent to servers\n    \n    func collectTrainingData(_ interaction: UserInteraction) {\n        // Store locally only\n        LocalDatabase.shared.saveInteraction(interaction)\n        \n        // Aggregate stats can be sent (differential privacy)\n        if shouldSendAggregate() {\n            sendAggregateStats()\n        }\n    }\n    \n    private func sendAggregateStats() {\n        // Only send counts, not individual data\n        let stats = AggregateStats(\n            totalInteractions: LocalDatabase.shared.interactionCount,\n            topFeatures: LocalDatabase.shared.featureUsageCounts.prefix(5),\n            avgSessionDuration: LocalDatabase.shared.avgSessionDuration\n        )\n        // Add noise for differential privacy\n        Analytics.track(\"aggregate_usage\", properties: stats.noisy())\n    }\n}\n```\n\n**Model Update Schedule:**\n```swift\nclass ModelUpdateScheduler {\n    func scheduleTraining() {\n        // Train weekly during charging + WiFi\n        BGTaskScheduler.shared.register(\n            forTaskWithIdentifier: \"com.app.ml-training\",\n            using: nil\n        ) { task in\n            self.performTraining(task: task as! BGProcessingTask)\n        }\n    }\n    \n    private func performTraining(task: BGProcessingTask) {\n        Task {\n            do {\n                try await trainer.updateModel(with: recentInteractions)\n                task.setTaskCompleted(success: true)\n            } catch {\n                task.setTaskCompleted(success: false)\n            }\n        }\n    }\n}\n```",
      "tags": ["personalization", "on-device-training", "ab-testing", "createml", "privacy"],
      "sources": ["https://developer.apple.com/documentation/createml"],
      "summary": "Train on-device with Create ML. A/B test: control vs ML vs rules. Track engagement metrics. Update weekly via BGTask during charging. All data stays on device."
    }
  ]
}
